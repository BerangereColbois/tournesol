{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# for adding the videos to DB\n",
    "# don't use at the same time with the server running\n",
    "# https://stackoverflow.com/questions/59119396/how-to-use-django-3-0-orm-in-a-jupyter-notebook-without-triggering-the-async-con\n",
    "import os\n",
    "from django.db.models import Count, Q, Func, FloatField, Value, Window\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "import numpy as np\n",
    "from django_react.settings import load_gin_config\n",
    "import gin\n",
    "from backend.ml_model.preference_aggregation_featureless import FeaturelessMedianPreferenceAverageRegularizationAggregator, loss_fcn, loss_fcn_gradient_hessian, variable_index_layer_call\n",
    "import string\n",
    "import shortuuid  # noqa: E402\n",
    "from backend.models import DjangoUser\n",
    "from backend.rating_fields import VIDEO_FIELDS\n",
    "from backend.ml_model.client_server.django_ml_featureless import DatabasePreferenceLearnerFeatureless\n",
    "import tensorflow as tf\n",
    "from annoying.functions import get_object_or_None\n",
    "from tqdm import tqdm\n",
    "load_gin_config('backend/ml_model/config/featureless_config.gin')\n",
    "gin.enter_interactive_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_alphanumeric(length=10, alphabet=None):\n",
    "    \"\"\"UUID1 without -.\"\"\"\n",
    "    if alphabet is None:\n",
    "        alphabet = string.ascii_lowercase + string.digits\n",
    "    res = shortuuid.ShortUUID(alphabet=alphabet).random(length=length)\n",
    "    return str(res).replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an expert\n",
    "e_username = random_alphanumeric()\n",
    "e_django = DjangoUser.objects.create_user(username=e_username)\n",
    "e = UserPreferences.objects.create(user=e_django) # INPUT FROM API\n",
    "e_ui = UserInformation.objects.create(user=e_django)\n",
    "domain = f\"@{random_alphanumeric()}.com\"\n",
    "EmailDomain.objects.create(domain=domain, status=EmailDomain.STATUS_ACCEPTED)\n",
    "email = VerifiableEmail.objects.create(user=e_ui, email=f\"test{domain}\", is_verified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_sample(arr, n):\n",
    "    \"\"\"Sample from an array, support non-integer arrays.\"\"\"\n",
    "    return [arr[i] for i in np.random.choice(range(len(arr)), n, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating videos, INPUT FROM API\n",
    "v = Video.objects.create(video_id=random_alphanumeric() + \"__v\")\n",
    "w = Video.objects.create(video_id=random_alphanumeric() + \"__w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating other videos to rate\n",
    "other_videos = Video.objects.bulk_create([Video(video_id=random_alphanumeric()) for _ in range(50)])\n",
    "other_videos = [Video.objects.get(video_id=v.video_id) for v in other_videos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rating(scale=1):\n",
    "    \"\"\"Return a random rating.\"\"\"\n",
    "    return {f: np.random.rand() * 100 * scale for f in VIDEO_FIELDS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating ratings for v\n",
    "for wother in array_sample(other_videos, 1):\n",
    "    r = random_rating()\n",
    "    y = ExpertRating.objects.create(user=e, video_1=v, video_2=wother, **r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating ratings for w\n",
    "for wother in array_sample(other_videos, 1):\n",
    "    r = random_rating()\n",
    "    y = ExpertRating.objects.create(user=e, video_1=w, video_2=wother, **r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling video rating data\n",
    "VideoRating.objects.create(user=e, video=v, **random_rating(scale=0.001))\n",
    "VideoRating.objects.create(user=e, video=w, **random_rating(scale=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, val in random_rating(scale=0.001).items():\n",
    "    setattr(v, k, val)\n",
    "v.save()\n",
    "for k, val in random_rating(scale=0.001).items():\n",
    "    setattr(w, k, val)\n",
    "w.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating for v/w\n",
    "ExpertRating.objects.create(user=e, video_1=v, video_2=w, **{f: 0 for f in VIDEO_FIELDS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT FROM API\n",
    "new_rating_vw = random_rating()\n",
    "# new expert rating, not saved yet\n",
    "new_rating = ExpertRating(user=e, video_1=v, video_2=w, **new_rating_vw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert str(gin.query_parameter('learner.cls')) == '@DatabasePreferenceLearnerFeatureless',\\\n",
    "    \"Only support featureless learner for online updates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Y_ev(e, v):\n",
    "    \"\"\"Videos rated with v together by e.\"\"\"\n",
    "    Y_ev = Video.objects.filter(Q(expertrating_video_1__video_2=v,\n",
    "                              expertrating_video_1__user=e)|\n",
    "                            Q(expertrating_video_2__video_1=v,\n",
    "                              expertrating_video_2__user=e)).distinct()\n",
    "    return Y_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_YEV = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yev_sampled = Y_ev(e, v).exclude(id=w.id).order_by('?')[:MAX_YEV]\n",
    "Yew_sampled = Y_ev(e, w).exclude(id=v.id).order_by('?')[:MAX_YEV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Yev_sampled[0]\n",
    "for k, val in random_rating(scale=0.01).items():\n",
    "    setattr(w1, k, val)\n",
    "w1.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yev_sampled, Yew_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of all videos used\n",
    "videos_subset = [v, w] + list(Yev_sampled) + list(Yew_sampled)\n",
    "videos_subset_v = [v, w] + list(Yev_sampled)\n",
    "videos_subset_w = [w, v] + list(Yew_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rating = ExpertRating.objects.filter(Q(video_1=v, video_2__in=Yev_sampled) |\n",
    "                                       Q(video_1__in=Yev_sampled, video_2=v))\n",
    "w_rating = ExpertRating.objects.filter(Q(video_1=w, video_2__in=Yew_sampled) |\n",
    "                                       Q(video_1__in=Yew_sampled, video_2=w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ratings = list(v_rating) + list(w_rating) + [new_rating]\n",
    "e_ratings_v = list(v_rating) + [new_rating]\n",
    "e_ratings_w = list(w_rating) + [new_rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_subset_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_subset_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ratings_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.bind_parameter('FeaturelessMedianPreferenceAverageRegularizationAggregator.epochs', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = DatabasePreferenceLearnerFeatureless(\n",
    "    load=False, save=False, user_queryset=[e],\n",
    "    video_queryset=videos_subset,\n",
    "    users_to_ratings={e.id: e_ratings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY V\n",
    "learner = DatabasePreferenceLearnerFeatureless(\n",
    "    load=False, save=False, user_queryset=[e],\n",
    "    video_queryset=videos_subset_v,\n",
    "    users_to_ratings={e.id: e_ratings_v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.aggregator.loss_fcn_kwargs(**learner.aggregator.hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.aggregator.loss_fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.users_to_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "learner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.users_to_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoRating.objects.get(video=v, user=e).features_as_vector\n",
    "\n",
    "# format: user, video, feature\n",
    "idxes = []\n",
    "values = []\n",
    "\n",
    "for video in learner.aggregator.all_ratings.objects:\n",
    "    video_id_internal = learner.aggregator.all_ratings.objects_reverse[video]\n",
    "    for user in learner.users + ['__aggregate_expert__']:\n",
    "        expert_id_internal = learner.aggregator.all_ratings.experts_reverse[user]\n",
    "        \n",
    "        r = None\n",
    "        if user == '__aggregate_expert__':\n",
    "            r = Video.objects.get(video_id=video).features_as_vector\n",
    "        else:\n",
    "            r = get_object_or_None(VideoRating, video__video_id=video, user=e)\n",
    "            if r:\n",
    "                r = r.features_as_vector\n",
    "        \n",
    "        if r is not None:\n",
    "            for i, val in enumerate(r):\n",
    "                if val is not None and not np.isnan(val):\n",
    "                    idxes.append((expert_id_internal, video_id_internal, i))\n",
    "                    values.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if idxes:\n",
    "    learner.aggregator.all_ratings.layer.v =\\\n",
    "        tf.Variable(tf.tensor_scatter_nd_update(\\\n",
    "        learner.aggregator.all_ratings.layer.v,\\\n",
    "        idxes, values), trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.all_ratings.experts_reverse, learner.all_ratings.objects_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids_vw = [learner.aggregator.all_ratings.objects_reverse[z.video_id] for z in [v, w]]\n",
    "vid_v_int, vid_w_int = video_ids_vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: disable in prod, as value might be non-existent\n",
    "check_values = True\n",
    "if check_values:\n",
    "    assert np.allclose(learner.all_ratings.layer.v[1, vid_v_int, :], v.features_as_vector)\n",
    "    assert np.allclose(learner.all_ratings.layer.v[1, vid_w_int, :], w.features_as_vector)\n",
    "\n",
    "    assert np.allclose(learner.all_ratings.layer.v[0, vid_v_int, :],\n",
    "                       VideoRating.objects.get(user=e, video=v).features_as_vector)\n",
    "    assert np.allclose(learner.all_ratings.layer.v[0, vid_w_int, :],\n",
    "                       VideoRating.objects.get(user=e, video=w).features_as_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.aggregator.all_ratings.layer.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = learner.aggregator.sample_minibatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not mb:\n",
    "    print(\"Minibatch is not valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_var = learner.aggregator.all_ratings.model.variables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del learner.aggregator.hypers['ignore_vals']# = ['model_tensor']\n",
    "\n",
    "loss_fcn_kwargs = learner.aggregator.loss_fcn_kwargs(**learner.aggregator.hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn(**mb, **loss_fcn_kwargs, model_tensor=r_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learner.aggregator.all_ratings.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = learner.aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal indices for experts and objects (ratings)\n",
    "idx_v1 = tf.stack((mb['experts_rating'], mb['objects_rating_v1']), axis=1)\n",
    "idx_v2 = tf.stack((mb['experts_rating'], mb['objects_rating_v2']), axis=1)\n",
    "\n",
    "# 2D array (comparison_id, feature) -> float\n",
    "theta_eqv = model(idx_v1)\n",
    "theta_eqw = model(idx_v2)\n",
    "theta_vw = theta_eqv - theta_eqw\n",
    "# print(theta_vw.shape, cmp.shape)\n",
    "theta_vw_y = tf.math.multiply(theta_vw, mb['cmp'])\n",
    "phi_eqvw = tf.exp(theta_vw_y)\n",
    "phi_eqvw_inv = 1 / phi_eqvw\n",
    "\n",
    "# value for the current video\n",
    "# model rating\n",
    "theta_eqv_video = model(tf.constant([0, 0]))\n",
    "# common rating\n",
    "s_eqv_video = model(tf.constant([1, 0]))\n",
    "# epsilon\n",
    "eps_eqv = tf.sign(theta_eqv_video - s_eqv_video)\n",
    "Yev_video = mb['num_ratings_all'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_ev = loss_fcn_kwargs['lambda_'] * Yev_video / (loss_fcn_kwargs['C'] + Yev_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_1 = tau_ev * eps_eqv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_eqv = tf.reduce_sum(mb['cmp'] / (1 + phi_eqvw_inv), axis=0)\n",
    "grad_2 = gamma_eqv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = grad_1 + grad_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_diag = tf.reduce_sum(mb['cmp'] ** 2 * phi_eqvw_inv / (1 + phi_eqvw_inv) ** 2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic gradient computation (slow due to diagnoal hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only learn scores for v, w for the user (not common)\n",
    "learn_mask = np.zeros_like(learner.aggregator.all_ratings.layer.v.numpy())\n",
    "learn_mask[0, video_ids_vw, :] = 1\n",
    "learn_mask = tf.constant(learn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit learner.aggregator.loss_fcn(**mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn_kwargs = learner.aggregator.loss_fcn_kwargs(**learner.aggregator.hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn(**mb, **loss_fcn_kwargs, model_tensor=r_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.aggregator.hypers['ignore_vals'] = ['model_tensor']\n",
    "loss_fcn_kwargs = learner.aggregator.loss_fcn_kwargs(**learner.aggregator.hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_var = tf.Variable(tf.constant(np.random.randn(*r_var.numpy().shape), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_var = learner.aggregator.all_ratings.layer.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def loss_fcn_gradient_hessian_11(video_indices, **kwargs):\n",
    "    \"\"\"Compute the loss function, gradient and the Hessian.\"\"\"\n",
    "    variable = kwargs['model_tensor']\n",
    "    loss = loss_fcn(**kwargs)['loss']\n",
    "    g = tf.gradients(loss, variable)[0]\n",
    "    g = tf.gather(g, axis=1, indices=video_indices)\n",
    "    h = tf.hessians(loss, variable)[0]\n",
    "    h = tf.gather(h, axis=1, indices=video_indices)\n",
    "    h = tf.gather(h, axis=4, indices=video_indices)\n",
    "    \n",
    "    s = tf.size(h[0, 0, 0])\n",
    "    h = tf.reshape(tf.linalg.diag_part(tf.reshape(h, (s, s))), h.shape[:3])\n",
    "    \n",
    "    return {'loss': loss, 'gradient': g, 'hessian_diag': h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgh = loss_fcn_gradient_hessian_11(model_tensor=r_var.value(), **mb, **loss_fcn_kwargs,\n",
    "           video_indices=tf.constant(video_ids_vw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_hessian = lgh['hessian_diag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit loss_fcn_gradient_hessian_11(model_tensor=r_var.value(), **mb, **loss_fcn_kwargs, video_indices=tf.constant(video_ids_vw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgh = loss_fcn_gradient_hessian(model_tensor=r_var.value(), **mb, **loss_fcn_kwargs,\n",
    "           video_indices=tf.constant(video_ids_vw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.log(np.abs(lgh['hessian'].numpy().reshape(28, 28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids_vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tensor = r_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def aaaaa():\n",
    "    \n",
    "#     def loss123(model_tensor):\n",
    "    # LOSS COMMON TO 0\n",
    "    experts_common_to_1 = loss_fcn_kwargs['aggregate_index'] * tf.ones(\n",
    "        shape=mb['objects_common_to_1'].shape, dtype=tf.int64)\n",
    "    idx_common_to_1 = tf.stack(\n",
    "        (experts_common_to_1, mb['objects_common_to_1']), axis=1)\n",
    "    s_qv_common_to_1 = variable_index_layer_call(model_tensor, idx_common_to_1)\n",
    "\n",
    "    sm1 = tf.math.square(s_qv_common_to_1 - loss_fcn_kwargs['default_score_value'])\n",
    "\n",
    "    # print(idx_common_to_1, s_qv_common_to_1, sm1)\n",
    "\n",
    "    cto1 = tf.reduce_sum(sm1) * loss_fcn_kwargs['mu']\n",
    "#     return cto1\n",
    "    \n",
    "    loss = cto1#loss123(model_tensor)\n",
    "    grad = tf.gradients(loss, model_tensor)[0]\n",
    "\n",
    "    \n",
    "    hess = tfp.math.diag_jacobian(xs=model_tensor, ys=grad)\n",
    "    \n",
    "    tf.print(grad)\n",
    "    tf.print(hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaaa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def loss_fcn_gradient_diag_hessian(video_indices, **kwargs):\n",
    "    \"\"\"Compute the loss function, gradient and the Hessian.\"\"\"\n",
    "    variable = kwargs['model_tensor']\n",
    "    loss = loss_fcn(**kwargs)['loss']\n",
    "    g = tf.gradients(loss, variable)[0]\n",
    "#     g_gather = tf.gather(g[0], axis=1, indices=video_indices)\n",
    "    _, h = tfp.math.diag_jacobian(ys=g, xs=variable, sample_shape=[1])\n",
    "    h = h[0]\n",
    "#     h = tf.gather(h, axis=1, indices=video_indices)\n",
    "    return {'loss': loss, 'gradient': g, 'diag_hessian': h}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_var = tf.Variable(tf.constant(np.random.randn(*r_var.numpy().shape), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgh = loss_fcn_gradient_diag_hessian(model_tensor=r_var.value(), **mb, **loss_fcn_kwargs, video_indices=tf.constant(video_ids_vw))\n",
    "lgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit loss_fcn_gradient_diag_hessian(model_tensor=r_var.value(), **mb, **loss_fcn_kwargs, video_indices=tf.constant(video_ids_vw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn(model_tensor=r_var.value(), **mb, **loss_fcn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_var = learner.aggregator.all_ratings.layer.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def loss_fcn_gradient_hessian_11(video_indices, **kwargs):\n",
    "    \"\"\"Compute the loss function, gradient and the Hessian.\"\"\"\n",
    "    variable = kwargs['model_tensor']\n",
    "    loss = loss_fcn(**kwargs)['loss']\n",
    "    g = tf.gradients(loss, variable)[0]\n",
    "#     g = tf.gather(g, axis=1, indices=video_indices)\n",
    "    h = tf.hessians(loss, variable)[0]\n",
    "#     h = tf.gather(h, axis=1, indices=video_indices)\n",
    "#     h = tf.gather(h, axis=4, indices=video_indices)\n",
    "    \n",
    "    s = tf.size(h[0, 0, 0])\n",
    "    h = tf.reshape(tf.linalg.diag_part(tf.reshape(h, (s, s))), h.shape[:3])\n",
    "    \n",
    "    return {'loss': loss, 'gradient': g, 'diag_hessian': h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "grads = []\n",
    "\n",
    "for _ in tqdm(range(500)):\n",
    "\n",
    "    lgh = loss_fcn_gradient_hessian_11(model_tensor=r_var.value(), **mb, **loss_fcn_kwargs,\n",
    "                                         video_indices=tf.constant(video_ids_vw))\n",
    "    \n",
    "#     print(lgh['hessian'].shape)\n",
    "#     orig_shape = lgh['hessian'].numpy().shape[:3]\n",
    "#     s = np.prod(orig_shape)\n",
    "#     print(orig_shape, s)\n",
    "    \n",
    "#     hess_reshape = lgh['hessian'].numpy().reshape((s, s))\n",
    "#     lgh['diag_hessian'] = tf.constant(np.diag(hess_reshape).reshape(orig_shape))\n",
    "\n",
    "    losses.append(lgh['loss'].numpy())\n",
    "\n",
    "    hess_lr = 1. / lgh['diag_hessian']\n",
    "    hess_lr_nonan = tf.raw_ops.Select(condition=tf.math.is_finite(hess_lr),\n",
    "                                      x=hess_lr, y=tf.zeros_like(hess_lr))\n",
    "\n",
    "    newton_grad = 0.01 * lgh['gradient'] * hess_lr_nonan\n",
    "\n",
    "    mask = np.zeros_like(newton_grad)\n",
    "    mask[0, 0, :] = 1\n",
    "\n",
    "    r_var = tf.Variable(tf.raw_ops.Select(condition=mask, x=r_var - newton_grad, y=r_var))\n",
    "\n",
    "    plt.hist(hess_lr_nonan[0, 0, :].numpy().flatten())\n",
    "    grads.append(np.linalg.norm(lgh['gradient'].numpy().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgh['diag_hessian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_lr_nonan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newton_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
